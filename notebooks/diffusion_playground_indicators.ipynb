{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import composuite\n",
    "from diffusion.utils import *\n",
    "from diffusion.elucidated_diffusion import Trainer\n",
    "from diffusion.train_diffuser import SimpleDiffusionGenerator\n",
    "\n",
    "gin.parse_config_file(\"/Users/shubhankar/Developer/compositional-rl-synth-data/config/diffusion.gin\")\n",
    "\n",
    "base_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/data'\n",
    "base_results_folder = '/Users/shubhankar/Developer/compositional-rl-synth-data/local_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'expert'\n",
    "\n",
    "robot = 'IIWA'\n",
    "obj = 'Box'\n",
    "obst = 'None'\n",
    "task = 'PickPlace'\n",
    "\n",
    "results_folder = os.path.join(base_results_folder, robot + '_' + obj + '_' + obst + '_' + task)\n",
    "\n",
    "dataset = load_single_composuite_dataset(base_path=base_data_path, \n",
    "                                         dataset_type=dataset_type, \n",
    "                                         robot=robot, obj=obj, \n",
    "                                         obst=obst, task=task)\n",
    "dataset = transitions_dataset(dataset)\n",
    "print('Before removing task indicators:', dataset['observations'].shape)\n",
    "env = composuite.make(robot, obj, obst, task, use_task_id_obs=True, ignore_done=False)\n",
    "dataset, indicators = remove_indicator_vectors(env.modality_dims, dataset)\n",
    "print('After removing task indicators:', dataset['observations'].shape)\n",
    "inputs = make_inputs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "task_vector = indicators[idx, :].reshape(1, -1)\n",
    "\n",
    "labels = ['Object', 'Robot', 'Obstacle', 'Subtask']\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.imshow(task_vector, cmap=\"viridis\", aspect=\"auto\")\n",
    "plt.colorbar(label=\"Value\")\n",
    "plt.xticks(ticks=[2, 6, 10, 14], labels=labels, ha='right')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs).float()\n",
    "indicators = torch.from_numpy(indicators).float()\n",
    "dataset = torch.utils.data.TensorDataset(inputs, indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = construct_diffusion_model(inputs=inputs, cond_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = 'compositional_diffusion_test'\n",
    "wandb_entity = ''\n",
    "wandb_group = 'diffusion_training'\n",
    "\n",
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    entity=wandb_entity,\n",
    "    group=wandb_group,\n",
    "    name=results_folder.split('/')[-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(diffusion, dataset, results_folder=results_folder)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gin.configurable\n",
    "class SimpleDiffusionGenerator:\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gym.Env,\n",
    "            ema_model,\n",
    "            num_sample_steps: int = 128,\n",
    "            sample_batch_size: int = 100000,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.diffusion = ema_model\n",
    "        self.diffusion.eval()\n",
    "        # Clamp samples if normalizer is MinMaxNormalizer\n",
    "        self.clamp_samples = isinstance(self.diffusion.normalizer, MinMaxNormalizer)\n",
    "        self.num_sample_steps = num_sample_steps\n",
    "        self.sample_batch_size = sample_batch_size\n",
    "        print(f'Sampling using: {self.num_sample_steps} steps, {self.sample_batch_size} batch size.')\n",
    "\n",
    "    def sample(\n",
    "            self,\n",
    "            num_samples: int,\n",
    "            cond: None,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \n",
    "        assert num_samples % self.sample_batch_size == 0, 'num_samples must be a multiple of sample_batch_size'\n",
    "\n",
    "        if cond is not None:\n",
    "            cond = torch.from_numpy(cond).float().to(self.diffusion.device)\n",
    "            cond = cond.unsqueeze(0).expand(self.sample_batch_size, -1)\n",
    "\n",
    "        num_batches = num_samples // self.sample_batch_size\n",
    "        observations = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_observations = []\n",
    "        terminals = []\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            print(f'Generating split {i + 1} of {num_batches}.')\n",
    "            sampled_outputs = self.diffusion.sample(\n",
    "                batch_size=self.sample_batch_size,\n",
    "                num_sample_steps=self.num_sample_steps,\n",
    "                clamp=self.clamp_samples,\n",
    "                cond=cond\n",
    "            )\n",
    "            sampled_outputs = sampled_outputs.cpu().numpy()\n",
    "\n",
    "            # Split samples into (s, a, r, s') format\n",
    "            transitions = split_diffusion_samples(sampled_outputs, self.env)\n",
    "            if len(transitions) == 4:\n",
    "                obs, act, rew, next_obs = transitions\n",
    "                terminal = np.zeros_like(next_obs[:, 0])\n",
    "            else:\n",
    "                obs, act, rew, next_obs, terminal = transitions\n",
    "            observations.append(obs)\n",
    "            actions.append(act)\n",
    "            rewards.append(rew)\n",
    "            next_observations.append(next_obs)\n",
    "            terminals.append(terminal)\n",
    "        observations = np.concatenate(observations, axis=0)\n",
    "        actions = np.concatenate(actions, axis=0)\n",
    "        rewards = np.concatenate(rewards, axis=0)\n",
    "        next_observations = np.concatenate(next_observations, axis=0)\n",
    "        terminals = np.concatenate(terminals, axis=0)\n",
    "\n",
    "        return observations, actions, rewards, next_observations, terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_indicator = get_task_indicator(robot, obj, obst, task)\n",
    "env = composuite.make(robot, obj, obst, task, use_task_id_obs=False, ignore_done=False)\n",
    "generator = SimpleDiffusionGenerator(env=env, ema_model=trainer.ema.ema_model)\n",
    "observations, actions, rewards, next_observations, terminals = generator.sample(num_samples=100000, cond=task_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    os.path.join(results_folder, 'samples.npz'),\n",
    "    observations=observations,\n",
    "    actions=actions,\n",
    "    rewards=rewards,\n",
    "    next_observations=next_observations,\n",
    "    terminals=terminals\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
