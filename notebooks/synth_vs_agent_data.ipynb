{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composuite\n",
    "from diffusion.utils import *\n",
    "from CORL.algorithms.offline.td3_bc import *\n",
    "from CORL.shared.buffer import *\n",
    "from CORL.shared.logger import *\n",
    "\n",
    "from diffusion.utils import *\n",
    "from collections import defaultdict\n",
    "import composuite\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = 'IIWA'\n",
    "obj = 'Box'\n",
    "obst = 'None'\n",
    "subtask = 'Trashcan'\n",
    "\n",
    "representative_indicators_env = composuite.make(robot, obj, obst, subtask, use_task_id_obs=True, ignore_done=False)\n",
    "modality_dims = representative_indicators_env.modality_dims\n",
    "\n",
    "\n",
    "base_agent_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/data'\n",
    "dataset = load_single_composuite_dataset(base_path=base_agent_data_path, \n",
    "                                            dataset_type='expert', \n",
    "                                            robot=robot, obj=obj, \n",
    "                                            obst=obst, task=subtask)\n",
    "agent_dataset = transitions_dataset(dataset)\n",
    "agent_dataset, _ = remove_indicator_vectors(modality_dims, agent_dataset)\n",
    "agent_obs = agent_dataset['observations']\n",
    "agent_actions = agent_dataset['actions']\n",
    "agent_next_obs = agent_dataset['next_observations']\n",
    "agent_rewards = agent_dataset['rewards']\n",
    "agent_terminals = agent_dataset['terminals']\n",
    "agent_dataset = make_inputs(agent_dataset)\n",
    "\n",
    "base_synthetic_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/cluster_results/diffusion/cond_diff_20/test/'\n",
    "synthetic_dataset = load_single_synthetic_dataset(base_path=base_synthetic_data_path, \n",
    "                                                  robot=robot, obj=obj, \n",
    "                                                  obst=obst, task=subtask)\n",
    "synthetic_obs = synthetic_dataset['observations']\n",
    "synthetic_actions = synthetic_dataset['actions']\n",
    "synthetic_next_obs = synthetic_dataset['next_observations']\n",
    "synthetic_rewards = synthetic_dataset['rewards']\n",
    "synthetic_terminals = synthetic_dataset['terminals']\n",
    "synthetic_dataset = make_inputs(synthetic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dataset.shape, synthetic_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_actions.shape, synthetic_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = composuite.make(robot, obj, obst, subtask, use_task_id_obs=False, ignore_done=False)\n",
    "print(env.modality_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_ranges = {}\n",
    "start_idx = 0\n",
    "for key, dim in env.modality_dims.items():\n",
    "    end_idx = start_idx + dim[0]\n",
    "    cumulative_ranges[key] = (start_idx, end_idx)\n",
    "    start_idx = end_idx\n",
    "\n",
    "dim_names = {}\n",
    "for dim, val_range in cumulative_ranges.items():\n",
    "    print(dim, val_range)\n",
    "    for idx in range(val_range[0], val_range[1]):\n",
    "        dim_names[idx] = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = agent_obs\n",
    "dataset2 = synthetic_obs\n",
    "\n",
    "num_dimensions = dataset1.shape[1]\n",
    "\n",
    "for idx in range(num_dimensions):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(dataset1[:, idx], bins=50, alpha=0.5, label='Agent', color='blue', density=True)\n",
    "    plt.hist(dataset2[:, idx], bins=50, alpha=0.5, label='Synthetic', color='orange', density=True)\n",
    "    plt.title(f\"{dim_names[idx]}, {idx+1}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean, state_std = compute_mean_std(agent_dataset, eps=1e-3)\n",
    "print(state_mean.mean(), state_std.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean, state_std = compute_mean_std(synthetic_dataset, eps=1e-3)\n",
    "print(state_mean.mean(), state_std.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(agent_dataset.shape[0], 1000, replace=False)\n",
    "sampled_agent_data = agent_dataset[random_indices]\n",
    "\n",
    "random_indices = np.random.choice(synthetic_dataset.shape[0], 1000, replace=False)\n",
    "sampled_synthetic_data = synthetic_dataset[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampled_agent_data.shape, sampled_synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(sampled_agent_data.shape[1]):\n",
    "    print(idx)\n",
    "    print('Mean:', sampled_agent_data[:, idx].mean(), sampled_synthetic_data[:, idx].mean())\n",
    "    print('Std:', sampled_agent_data[:, idx].std(), sampled_synthetic_data[:, idx].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((sampled_agent_data, sampled_synthetic_data), axis=0)\n",
    "\n",
    "agent_origin = np.zeros(sampled_agent_data.shape[0], dtype=int)  # 0 for expert\n",
    "synthetic_origin = np.ones(sampled_synthetic_data.shape[0], dtype=int)   # 1 for synthetic\n",
    "combined_origins = np.concatenate((agent_origin, synthetic_origin), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = StandardScaler().fit_transform(combined_data)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings = tsne.fit_transform(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings[combined_origins == 0, 0], embeddings[combined_origins == 0, 1], \n",
    "            c='blue', label='Agent', alpha=0.6, edgecolor='k', s=20)\n",
    "plt.scatter(embeddings[combined_origins == 1, 0], embeddings[combined_origins == 1, 1], \n",
    "            c='red', label='Diffusion', alpha=0.6, edgecolor='k', s=20)\n",
    "plt.title('t-SNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
