{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composuite\n",
    "from diffusion.utils import *\n",
    "from CORL.algorithms.offline.td3_bc import *\n",
    "from CORL.shared.buffer import *\n",
    "from CORL.shared.logger import *\n",
    "\n",
    "from diffusion.utils import *\n",
    "from collections import defaultdict\n",
    "import composuite\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def transitions_dataset(dataset):\n",
    "    \"\"\"\n",
    "    https://github.com/Farama-Foundation/D4RL/blob/89141a689b0353b0dac3da5cba60da4b1b16254d/d4rl/__init__.py#L69\n",
    "    \"\"\"\n",
    "\n",
    "    N = dataset['rewards'].shape[0]\n",
    "\n",
    "    obs_ = []\n",
    "    next_obs_ = []\n",
    "    action_ = []\n",
    "    reward_ = []\n",
    "    terminal_ = []\n",
    "    timestep_ = []\n",
    "\n",
    "    timestep = 0\n",
    "    for i in range(N - 1):\n",
    "        obs = dataset['observations'][i].astype(np.float32)\n",
    "        new_obs = dataset['observations'][i + 1].astype(np.float32)\n",
    "        action = dataset['actions'][i].astype(np.float32)\n",
    "        reward = dataset['rewards'][i].astype(np.float32)\n",
    "        done_bool = bool(dataset['terminals'][i])\n",
    "        final_timestep = dataset['timeouts'][i]\n",
    "        terminal = done_bool or final_timestep\n",
    "\n",
    "        obs_.append(obs)\n",
    "        next_obs_.append(new_obs)\n",
    "        action_.append(action)\n",
    "        reward_.append(reward)\n",
    "        terminal_.append(terminal)\n",
    "        timestep_.append(timestep)\n",
    "\n",
    "        timestep = 0 if terminal else timestep + 1\n",
    "\n",
    "    return {\n",
    "        'observations': np.array(obs_),\n",
    "        'actions': np.array(action_),\n",
    "        'next_observations': np.array(next_obs_),\n",
    "        'rewards': np.array(reward_),\n",
    "        'terminals': np.array(terminal_),\n",
    "        'timesteps': np.array(timestep_),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = 'Kinova3'\n",
    "obj = 'Hollowbox'\n",
    "obst = 'None'\n",
    "subtask = 'Trashcan'\n",
    "\n",
    "representative_indicators_env = composuite.make(robot, obj, obst, subtask, use_task_id_obs=True, ignore_done=False)\n",
    "modality_dims = representative_indicators_env.modality_dims\n",
    "\n",
    "base_agent_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/data'\n",
    "dataset = load_single_composuite_dataset(base_path=base_agent_data_path, \n",
    "                                            dataset_type='expert', \n",
    "                                            robot=robot, obj=obj, \n",
    "                                            obst=obst, task=subtask)                                        \n",
    "agent_dataset = transitions_dataset(dataset)\n",
    "agent_dataset, _ = remove_indicator_vectors(modality_dims, agent_dataset)\n",
    "agent_obs = agent_dataset['observations']\n",
    "agent_actions = agent_dataset['actions']\n",
    "agent_next_obs = agent_dataset['next_observations']\n",
    "agent_rewards = agent_dataset['rewards']\n",
    "agent_terminals = agent_dataset['terminals']\n",
    "agent_timesteps = agent_dataset['timesteps']\n",
    "agent_dataset = make_inputs(agent_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper_closed = np.argmax(agent_actions, axis=1) == 7  # gripper action\n",
    "print(gripper_closed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(agent_dataset.shape[0], 2500, replace=False)\n",
    "sampled_timesteps = agent_timesteps[random_indices]\n",
    "sampled_gripper = gripper_closed[random_indices]\n",
    "sampled_agent_data = agent_dataset[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampled_timesteps.shape, sampled_gripper.shape, sampled_agent_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = StandardScaler().fit_transform(sampled_agent_data)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings = tsne.fit_transform(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], \n",
    "                      c=sampled_timesteps, cmap='viridis', alpha=0.8)\n",
    "plt.colorbar(scatter, label=\"Timestep\")\n",
    "plt.scatter(embeddings[sampled_gripper, 0], embeddings[sampled_gripper, 1], \n",
    "            color='red', marker='x', label='Gripper Closed')\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.title(\"t-SNE colored by Timestep\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
