{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composuite\n",
    "from diffusion.utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def compute_error(agent_dataset, synthetic_dataset):\n",
    "\n",
    "    num_samples = 1000\n",
    "    \n",
    "    agent_observations = agent_dataset['observations']\n",
    "    random_indices = np.random.choice(agent_observations.shape[0], num_samples, replace=False)\n",
    "    sampled_agent_observations = agent_observations[random_indices]\n",
    "\n",
    "    synthetic_observations = synthetic_dataset['observations']\n",
    "    random_indices = np.random.choice(synthetic_observations.shape[0], num_samples, replace=False)\n",
    "    sampled_synthetic_observations = synthetic_observations[random_indices]\n",
    "\n",
    "    mean_agent = np.mean(sampled_agent_observations, axis=0)\n",
    "    mean_synthetic = np.mean(sampled_synthetic_observations, axis=0)\n",
    "\n",
    "    error = np.linalg.norm(mean_agent - mean_synthetic)\n",
    "    \n",
    "    return error\n",
    "\n",
    "\n",
    "def wasserstein_distance(agent_dataset, synthetic_dataset, key='observations', num_samples=1000):\n",
    "    \n",
    "    agent_data = agent_dataset[key]\n",
    "    random_indices = np.random.choice(agent_data.shape[0], num_samples, replace=False)\n",
    "    sampled_agent_data = agent_data[random_indices]\n",
    "\n",
    "    synthetic_data = synthetic_dataset[key]\n",
    "    random_indices = np.random.choice(synthetic_data.shape[0], num_samples, replace=False)\n",
    "    sampled_synthetic_data = synthetic_data[random_indices]\n",
    "    \n",
    "    n_dims = sampled_agent_data.shape[1]\n",
    "    w_distances = []\n",
    "    \n",
    "    for dim in range(n_dims):\n",
    "        w_dist = stats.wasserstein_distance(sampled_agent_data[:, dim], sampled_synthetic_data[:, dim])\n",
    "        w_distances.append(w_dist)\n",
    "    \n",
    "    return np.mean(w_distances), w_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'expert'\n",
    "base_agent_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/data'\n",
    "# base_synthetic_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/cluster_results/Quan/180M/'\n",
    "base_synthetic_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/cluster_results/diffusion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_indicators_env = composuite.make('IIWA', 'Plate', 'ObjectWall', 'Push', use_task_id_obs=True, ignore_done=False)\n",
    "representative_env = composuite.make('IIWA', 'Plate', 'ObjectWall', 'Push', use_task_id_obs=False, ignore_done=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['cond_diff_17', 'cond_diff_7', 'cond_diff_8', \n",
    "        'cond_diff_10', 'cond_diff_15', 'cond_diff_19', \n",
    "        'cond_diff_22', 'cond_diff_18', 'cond_diff_23', \n",
    "        'cond_diff_20', 'cond_diff_24', 'cond_diff_25', \n",
    "        'cond_diff_21']\n",
    "num_train_tasks = [16, 32, 48, 64, 80, 96, 112, 128, 144, 176, 192, 208, 244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_obs_means = []\n",
    "all_train_obs_stds = []\n",
    "all_test_obs_means = []\n",
    "all_test_obs_stds = []\n",
    "\n",
    "all_train_act_means = []\n",
    "all_train_act_stds = []\n",
    "all_test_act_means = []\n",
    "all_test_act_stds = []\n",
    "\n",
    "all_train_obs_per_dim = []\n",
    "all_test_obs_per_dim = []\n",
    "all_train_act_per_dim = []\n",
    "all_test_act_per_dim = []\n",
    "\n",
    "for run in tqdm(runs, desc='Run'):\n",
    "    train_tasks = [\n",
    "        task for task in os.listdir(os.path.join(base_synthetic_data_path, run, 'train'))\n",
    "        if not task.startswith('.')\n",
    "    ]\n",
    "    obs_errors = []\n",
    "    act_errors = []\n",
    "    obs_per_dim_errors = []\n",
    "    act_per_dim_errors = []\n",
    "    \n",
    "    for task in train_tasks:\n",
    "        robot, obj, obst, subtask = task.split('_')\n",
    "        agent_dataset = load_single_composuite_dataset(base_path=base_agent_data_path, \n",
    "                                                       dataset_type='expert', \n",
    "                                                       robot=robot, obj=obj, \n",
    "                                                       obst=obst, task=subtask)\n",
    "        agent_dataset = transitions_dataset(agent_dataset)\n",
    "        agent_dataset, _ = remove_indicator_vectors(representative_indicators_env.modality_dims, agent_dataset)\n",
    "\n",
    "        synthetic_dataset = load_single_synthetic_dataset(base_path=os.path.join(base_synthetic_data_path, run, 'train'),\n",
    "                                                          robot=robot, obj=obj, \n",
    "                                                          obst=obst, task=subtask)\n",
    "        \n",
    "        # Compute Wasserstein distance for observations (mean and per-dimension)\n",
    "        mean_obs_dist, obs_dists = wasserstein_distance(agent_dataset, synthetic_dataset, key='observations')\n",
    "        obs_errors.append(mean_obs_dist)\n",
    "        obs_per_dim_errors.append(np.array(obs_dists))\n",
    "        \n",
    "        # Compute Wasserstein distance for actions (mean and per-dimension)\n",
    "        mean_act_dist, act_dists = wasserstein_distance(agent_dataset, synthetic_dataset, key='actions')\n",
    "        act_errors.append(mean_act_dist)\n",
    "        act_per_dim_errors.append(np.array(act_dists))\n",
    "    \n",
    "    all_train_obs_means.append(np.mean(obs_errors))\n",
    "    all_train_obs_stds.append(np.std(obs_errors))\n",
    "    all_train_act_means.append(np.mean(act_errors))\n",
    "    all_train_act_stds.append(np.std(act_errors))\n",
    "    \n",
    "    # Compute average per-dimension errors across all train tasks\n",
    "    all_train_obs_per_dim.append(np.mean(np.stack(obs_per_dim_errors, axis=0), axis=0))\n",
    "    all_train_act_per_dim.append(np.mean(np.stack(act_per_dim_errors, axis=0), axis=0))\n",
    "\n",
    "    test_tasks = [\n",
    "        task for task in os.listdir(os.path.join(base_synthetic_data_path, run, 'test'))\n",
    "        if not task.startswith('.')\n",
    "    ]\n",
    "    obs_errors = []\n",
    "    act_errors = []\n",
    "    obs_per_dim_errors = []\n",
    "    act_per_dim_errors = []\n",
    "    \n",
    "    for task in test_tasks:\n",
    "        robot, obj, obst, subtask = task.split('_')\n",
    "        agent_dataset = load_single_composuite_dataset(base_path=base_agent_data_path, \n",
    "                                                       dataset_type='expert', \n",
    "                                                       robot=robot, obj=obj, \n",
    "                                                       obst=obst, task=subtask)\n",
    "        agent_dataset = transitions_dataset(agent_dataset)\n",
    "        agent_dataset, _ = remove_indicator_vectors(representative_indicators_env.modality_dims, agent_dataset)\n",
    "\n",
    "        synthetic_dataset = load_single_synthetic_dataset(base_path=os.path.join(base_synthetic_data_path, run, 'test'),\n",
    "                                                        robot=robot, obj=obj, \n",
    "                                                        obst=obst, task=subtask)\n",
    "        \n",
    "        # Compute Wasserstein distance for observations (mean and per-dimension)\n",
    "        mean_obs_dist, obs_dists = wasserstein_distance(agent_dataset, synthetic_dataset, key='observations')\n",
    "        obs_errors.append(mean_obs_dist)\n",
    "        obs_per_dim_errors.append(np.array(obs_dists))\n",
    "        \n",
    "        # Compute Wasserstein distance for actions (mean and per-dimension)\n",
    "        mean_act_dist, act_dists = wasserstein_distance(agent_dataset, synthetic_dataset, key='actions')\n",
    "        act_errors.append(mean_act_dist)\n",
    "        act_per_dim_errors.append(np.array(act_dists))\n",
    "    \n",
    "    all_test_obs_means.append(np.mean(obs_errors))\n",
    "    all_test_obs_stds.append(np.std(obs_errors))\n",
    "    all_test_act_means.append(np.mean(act_errors))\n",
    "    all_test_act_stds.append(np.std(act_errors))\n",
    "    \n",
    "    # Compute average per-dimension errors across all test tasks\n",
    "    all_test_obs_per_dim.append(np.mean(np.stack(obs_per_dim_errors, axis=0), axis=0))\n",
    "    all_test_act_per_dim.append(np.mean(np.stack(act_per_dim_errors, axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "all_train_obs_means = np.array(all_train_obs_means)\n",
    "all_train_obs_stds = np.array(all_train_obs_stds)\n",
    "all_test_obs_means = np.array(all_test_obs_means)\n",
    "all_test_obs_stds = np.array(all_test_obs_stds)\n",
    "all_train_act_means = np.array(all_train_act_means)\n",
    "all_train_act_stds = np.array(all_train_act_stds)\n",
    "all_test_act_means = np.array(all_test_act_means)\n",
    "all_test_act_stds = np.array(all_test_act_stds)\n",
    "\n",
    "# Plot observation errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(num_train_tasks, all_train_obs_means, label='Train Error', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(num_train_tasks, all_test_obs_means, label='Test Error', marker='s', linestyle='-', color='orange')\n",
    "\n",
    "plt.fill_between(\n",
    "    num_train_tasks,\n",
    "    all_train_obs_means - all_train_obs_stds,\n",
    "    all_train_obs_means + all_train_obs_stds,\n",
    "    color='blue', alpha=0.4\n",
    ")\n",
    "plt.fill_between(\n",
    "    num_train_tasks,\n",
    "    all_test_obs_means - all_test_obs_stds,\n",
    "    all_test_obs_means + all_test_obs_stds,\n",
    "    color='orange', alpha=0.4\n",
    ")\n",
    "\n",
    "plt.xlabel('Number of Training Tasks', fontsize=14)\n",
    "plt.ylabel('Observation Wasserstein Distance', fontsize=14)\n",
    "plt.title('Diffusion Model Generalization - Observations', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot action errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(num_train_tasks, all_train_act_means, label='Train Error', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(num_train_tasks, all_test_act_means, label='Test Error', marker='s', linestyle='-', color='orange')\n",
    "\n",
    "plt.fill_between(\n",
    "    num_train_tasks,\n",
    "    all_train_act_means - all_train_act_stds,\n",
    "    all_train_act_means + all_train_act_stds,\n",
    "    color='blue', alpha=0.4\n",
    ")\n",
    "plt.fill_between(\n",
    "    num_train_tasks,\n",
    "    all_test_act_means - all_test_act_stds,\n",
    "    all_test_act_means + all_test_act_stds,\n",
    "    color='orange', alpha=0.4\n",
    ")\n",
    "\n",
    "plt.xlabel('Number of Training Tasks', fontsize=14)\n",
    "plt.ylabel('Action Wasserstein Distance', fontsize=14)\n",
    "plt.title('Diffusion Model Generalization - Actions', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For observations\n",
    "modality_dims = representative_env.modality_dims\n",
    "\n",
    "dim_names = []\n",
    "start_idx = 0\n",
    "\n",
    "for modality, (size,) in modality_dims.items():\n",
    "    for i in range(size):\n",
    "        dim_names.append(f\"{modality} {i}\")\n",
    "    start_idx += size\n",
    "\n",
    "# Convert to numpy arrays\n",
    "train_obs_per_dim = np.array(all_train_obs_per_dim)\n",
    "test_obs_per_dim = np.array(all_test_obs_per_dim)\n",
    "\n",
    "n_dims = train_obs_per_dim.shape[1]  # Number of dimensions\n",
    "n_cols = 3  # Number of columns in grid\n",
    "n_rows = 3  # Number of rows per figure\n",
    "\n",
    "dims_per_figure = n_cols * n_rows\n",
    "total_figures = (n_dims + dims_per_figure - 1) // dims_per_figure\n",
    "\n",
    "print(\"Plotting observation dimensions...\")\n",
    "for fig_idx in range(total_figures):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    start_dim = fig_idx * dims_per_figure\n",
    "    end_dim = min(start_dim + dims_per_figure, n_dims)\n",
    "    \n",
    "    for i, dim_idx in enumerate(range(start_dim, end_dim)):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        train_dim_data = train_obs_per_dim[:, dim_idx]\n",
    "        test_dim_data = test_obs_per_dim[:, dim_idx]\n",
    "        \n",
    "        # Get the dimension name\n",
    "        dim_name = dim_names[dim_idx] if dim_idx < len(dim_names) else f\"Unknown {dim_idx}\"\n",
    "        \n",
    "        plt.plot(num_train_tasks, train_dim_data, label='Train', marker='o', linestyle='-', color='blue')\n",
    "        plt.plot(num_train_tasks, test_dim_data, label='Test', marker='s', linestyle='-', color='orange')\n",
    "        \n",
    "        plt.xlabel('# Tasks', fontsize=10)\n",
    "        plt.ylabel('W-Distance', fontsize=10)\n",
    "        plt.title(f\"Obs Dim {dim_idx}: {dim_name}\", fontsize=11)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# For actions\n",
    "train_act_per_dim = np.array(all_train_act_per_dim)\n",
    "test_act_per_dim = np.array(all_test_act_per_dim)\n",
    "\n",
    "n_dims = train_act_per_dim.shape[1]  # Number of dimensions\n",
    "\n",
    "print(\"Plotting action dimensions...\")\n",
    "for fig_idx in range(total_figures):\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    start_dim = fig_idx * dims_per_figure\n",
    "    end_dim = min(start_dim + dims_per_figure, n_dims)\n",
    "    \n",
    "    for i, dim_idx in enumerate(range(start_dim, end_dim)):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        train_dim_data = train_act_per_dim[:, dim_idx]\n",
    "        test_dim_data = test_act_per_dim[:, dim_idx]\n",
    "        \n",
    "        # Get the dimension name for actions\n",
    "        act_name = f\"Action {dim_idx}\"\n",
    "        \n",
    "        plt.plot(num_train_tasks, train_dim_data, label='Train', marker='o', linestyle='-', color='blue')\n",
    "        plt.plot(num_train_tasks, test_dim_data, label='Test', marker='s', linestyle='-', color='orange')\n",
    "        \n",
    "        plt.xlabel('# Tasks', fontsize=10)\n",
    "        plt.ylabel('W-Distance', fontsize=10)\n",
    "        plt.title(f\"Act Dim {dim_idx}: {act_name}\", fontsize=11)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_to_modality = {}\n",
    "start_idx = 0\n",
    "for modality, (size,) in modality_dims.items():\n",
    "    for i in range(size):\n",
    "        dim_to_modality[start_idx + i] = modality\n",
    "    start_idx += size\n",
    "\n",
    "train_obs_per_dim = np.array(all_train_obs_per_dim)\n",
    "test_obs_per_dim = np.array(all_test_obs_per_dim)\n",
    "\n",
    "print(\"Plotting observations grouped by modality...\")\n",
    "for modality, (size,) in modality_dims.items():\n",
    "\n",
    "    modality_indices = [i for i, mod in dim_to_modality.items() if mod == modality]\n",
    "    n_dims = len(modality_indices)\n",
    "    \n",
    "    n_cols = 3\n",
    "    n_rows = (n_dims + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    for i, dim_idx in enumerate(modality_indices):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        train_dim_data = train_obs_per_dim[:, dim_idx]\n",
    "        test_dim_data = test_obs_per_dim[:, dim_idx]\n",
    "        \n",
    "        plt.plot(num_train_tasks, train_dim_data, label='Train', marker='o', linestyle='-', color='blue')\n",
    "        plt.plot(num_train_tasks, test_dim_data, label='Test', marker='s', linestyle='-', color='orange')\n",
    "        \n",
    "        plt.xlabel('# Tasks', fontsize=10)\n",
    "        plt.ylabel('W-Distance', fontsize=10)\n",
    "        plt.title(f\"{modality} {dim_idx - modality_indices[0]}\", fontsize=11)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.suptitle(f\"{modality} dimensions\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
