{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composuite\n",
    "from diffusion.utils import *\n",
    "from corl.algorithms.offline.td3_bc import *\n",
    "from corl.shared.buffer import *\n",
    "from corl.shared.logger import *\n",
    "\n",
    "from diffusion.utils import *\n",
    "from collections import defaultdict\n",
    "import composuite\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "def transitions_dataset_with_timesteps(dataset):\n",
    "    \"\"\"\n",
    "    https://github.com/Farama-Foundation/D4RL/blob/89141a689b0353b0dac3da5cba60da4b1b16254d/d4rl/__init__.py#L69\n",
    "    \"\"\"\n",
    "\n",
    "    N = dataset['rewards'].shape[0]\n",
    "\n",
    "    obs_ = []\n",
    "    next_obs_ = []\n",
    "    action_ = []\n",
    "    reward_ = []\n",
    "    terminal_ = []\n",
    "    timestep_ = []\n",
    "\n",
    "    timestep = 0\n",
    "    for i in range(N - 1):\n",
    "        obs = dataset['observations'][i].astype(np.float32)\n",
    "        new_obs = dataset['observations'][i + 1].astype(np.float32)\n",
    "        action = dataset['actions'][i].astype(np.float32)\n",
    "        reward = dataset['rewards'][i].astype(np.float32)\n",
    "        done_bool = bool(dataset['terminals'][i])\n",
    "        final_timestep = dataset['timeouts'][i]\n",
    "        terminal = done_bool or final_timestep\n",
    "\n",
    "        obs_.append(obs)\n",
    "        next_obs_.append(new_obs)\n",
    "        action_.append(action)\n",
    "        reward_.append(reward)\n",
    "        terminal_.append(terminal)\n",
    "        timestep_.append(timestep)\n",
    "\n",
    "        timestep = 0 if terminal else timestep + 1\n",
    "\n",
    "    return {\n",
    "        'observations': np.array(obs_),\n",
    "        'actions': np.array(action_),\n",
    "        'next_observations': np.array(next_obs_),\n",
    "        'rewards': np.array(reward_),\n",
    "        'terminals': np.array(terminal_),\n",
    "        'timesteps': np.array(timestep_),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = 'IIWA'\n",
    "obj = 'Dumbbell'\n",
    "obst = 'ObjectDoor'\n",
    "subtask = 'Trashcan'\n",
    "\n",
    "# robot = 'Kinova3'\n",
    "# obj = 'Hollowbox'\n",
    "# obst = 'None'\n",
    "# subtask = 'Trashcan'\n",
    "\n",
    "# robot = 'Jaco'\n",
    "# obj = 'Plate'\n",
    "# obst = 'GoalWall'\n",
    "# subtask = 'Shelf'\n",
    "\n",
    "# robot = 'Panda'\n",
    "# obj = 'Hollowbox'\n",
    "# obst = 'ObjectDoor'\n",
    "# subtask = 'Trashcan'\n",
    "\n",
    "representative_indicators_env = composuite.make(robot, obj, obst, subtask, use_task_id_obs=True, ignore_done=False)\n",
    "modality_dims = representative_indicators_env.modality_dims\n",
    "\n",
    "\n",
    "base_agent_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/data'\n",
    "dataset = load_single_composuite_dataset(base_path=base_agent_data_path, \n",
    "                                            dataset_type='expert', \n",
    "                                            robot=robot, obj=obj, \n",
    "                                            obst=obst, task=subtask)\n",
    "agent_dataset = transitions_dataset_with_timesteps(dataset)\n",
    "agent_dataset, _ = remove_indicator_vectors(modality_dims, agent_dataset)\n",
    "agent_obs = agent_dataset['observations']\n",
    "agent_actions = agent_dataset['actions']\n",
    "agent_next_obs = agent_dataset['next_observations']\n",
    "agent_rewards = agent_dataset['rewards']\n",
    "agent_terminals = agent_dataset['terminals']\n",
    "agent_timesteps = agent_dataset['timesteps']\n",
    "# agent_dataset = make_inputs(agent_dataset)\n",
    "agent_dataset = agent_next_obs\n",
    "\n",
    "base_synthetic_data_path = '/Users/shubhankar/Developer/compositional-rl-synth-data/cluster_results/diffusion/cond_diff_20/train/'\n",
    "synthetic_dataset = load_single_synthetic_dataset(base_path=base_synthetic_data_path, \n",
    "                                                  robot=robot, obj=obj, \n",
    "                                                  obst=obst, task=subtask)\n",
    "synthetic_obs = synthetic_dataset['observations']\n",
    "synthetic_actions = synthetic_dataset['actions']\n",
    "synthetic_next_obs = synthetic_dataset['next_observations']\n",
    "synthetic_rewards = synthetic_dataset['rewards']\n",
    "synthetic_terminals = synthetic_dataset['terminals']\n",
    "# synthetic_dataset = make_inputs(synthetic_dataset)\n",
    "synthetic_dataset = synthetic_next_obs\n",
    "\n",
    "print(agent_dataset.shape, synthetic_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_gripper = np.argmax(agent_actions, axis=1) == 7  # gripper action\n",
    "synthetic_gripper = np.argmax(synthetic_actions, axis=1) == 7\n",
    "print(agent_gripper.shape, synthetic_gripper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = composuite.make(robot, obj, obst, subtask, use_task_id_obs=False, ignore_done=False)\n",
    "print(env.modality_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(agent_dataset.shape[0], 2500, replace=False)\n",
    "sampled_agent_data = agent_dataset[random_indices]\n",
    "sampled_agent_gripper = agent_gripper[random_indices]\n",
    "sampled_agent_timesteps = agent_timesteps[random_indices]\n",
    "\n",
    "random_indices = np.random.choice(synthetic_dataset.shape[0], 2500, replace=False)\n",
    "sampled_synthetic_data = synthetic_dataset[random_indices]\n",
    "sampled_synthetic_gripper = synthetic_gripper[random_indices]\n",
    "\n",
    "print(sampled_agent_data.shape, sampled_synthetic_data.shape)\n",
    "print(sampled_agent_gripper.shape, sampled_synthetic_gripper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(sampled_agent_data)\n",
    "scaled_agent_data = scaler.transform(sampled_agent_data)\n",
    "scaled_synthetic_data = scaler.transform(sampled_synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_components=2).fit(scaled_agent_data)\n",
    "embedded_agent_data = umap_model.transform(scaled_agent_data)\n",
    "embedded_synthetic_data = umap_model.transform(scaled_synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "scatter = axes[0].scatter(embedded_agent_data[:, 0], embedded_agent_data[:, 1], \n",
    "                          c=sampled_agent_timesteps, cmap='viridis', alpha=0.8)\n",
    "fig.colorbar(scatter, ax=axes[0], label=\"Timestep\")\n",
    "axes[0].scatter(embedded_agent_data[sampled_agent_gripper, 0], \n",
    "                embedded_agent_data[sampled_agent_gripper, 1], \n",
    "                c='#ff7f0e', marker='x', s=50, label='Gripper Closed')\n",
    "axes[0].set_title('Fit-Transformed Agent Data', fontsize=14)\n",
    "axes[0].set_xlabel('Dimension 1', fontsize=14)\n",
    "axes[0].set_ylabel('Dimension 2', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].scatter(embedded_synthetic_data[:, 0], embedded_synthetic_data[:, 1], \n",
    "                c='#1f77b4', alpha=0.6, edgecolor='k', s=20)\n",
    "axes[1].scatter(embedded_synthetic_data[sampled_synthetic_gripper, 0], \n",
    "                embedded_synthetic_data[sampled_synthetic_gripper, 1], \n",
    "                c='#ff7f0e', marker='x', s=50, label='Gripper Closed')\n",
    "axes[1].set_title('Transformed Synthetic Data', fontsize=14)\n",
    "axes[1].set_xlabel('Dimension 1', fontsize=14)\n",
    "axes[1].set_ylabel('Dimension 2', fontsize=14)\n",
    "axes[1].legend()\n",
    "\n",
    "fig.suptitle(f\"Train Task: {robot}_{obj}_{obst}_{subtask}\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = f\"umap_{robot}_{obj}_{obst}_{subtask}.png\"\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
